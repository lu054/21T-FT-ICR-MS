{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# 1. Load Files Here: (extension name needed)\n",
    "input_folder = 'ESI+_1_sus_screening_0p2ppm/raw/'\n",
    "output_folder = 'ESI+_9_NIST_0p2ppm/'\n",
    "csv_files = glob.glob(os.path.join(input_folder, '*.csv'))\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for input_file_path in csv_files:\n",
    "    # Raw Data:\n",
    "    input_file = pd.read_csv(input_file_path, skiprows=6).dropna()\n",
    "    # Library File:\n",
    "    library_file = pd.read_csv('../PFAS_libraries/NIST_PFAS_Suspect_List_pos.csv')\n",
    "    # Output File:\n",
    "    output_file_name = os.path.splitext(os.path.basename(input_file_path))[0] + '_known.csv'\n",
    "    output_file = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "    # 2. Set Parameters Here:\n",
    "    S_to_N_threshold = 3\n",
    "    ppm_error = 0.2\n",
    "    PROTON = 1.00727647\n",
    "    SODIUM = 22.989769\n",
    "    POTASSIUM = 38.963706\n",
    "    \n",
    "    # 3. Input File Peaks List\n",
    "    ## 3a. Check input file\n",
    "    # input_file = input_file.loc[input_file['S/N'] >= S_to_N_threshold, :]\n",
    "    raw_pks = len(input_file.index)\n",
    "    \n",
    "    ## 3b. Convert all of the uppercase column labels to lowercase and replace the spaces with `_`.\n",
    "    input_file.columns = (\n",
    "        input_file.columns.str.lower()\n",
    "        .str.strip()\n",
    "        .str.replace(r'\\s+', '_', regex=True)\n",
    "    )\n",
    "    input_file['nominal_mass'] = round(input_file['peak_location']).astype(int)\n",
    "    \n",
    "    ## 3c. Calculate experimental KMD values of CF2, CH2, and C2H4O series\n",
    "    input_file['KMD_CF2'] = (input_file['peak_location'].round() - input_file['peak_location']*50/49.99681).round(4)\n",
    "    input_file['KMD_CH2'] = (input_file['peak_location'].round() - input_file['peak_location']*14/14.01565).round(4)\n",
    "    input_file['KMD_C2H4O'] = (input_file['peak_location'].round() - input_file['peak_location']*44/44.02621).round(4)\n",
    "    \n",
    "    # 4. Library Peak List\n",
    "    ## 4a. Check library file\n",
    "    lib_pks = len(library_file.index)\n",
    "    library_file.shape\n",
    "    # Convert all of the uppercase column labels to lowercase and replace the spaces with `_`.\n",
    "    library_file.columns = (\n",
    "        library_file.columns.str.lower()\n",
    "        .str.strip()\n",
    "        .str.replace(r'\\s+', '_', regex=True)\n",
    "    )\n",
    "    \n",
    "    ## 4b. Compute protonated/deprotonated mass of the library\n",
    "    list_suspects = library_file.assign(\n",
    "        mz_pos_H = library_file.loc[:, 'mass'] + PROTON,\n",
    "        nominal_mz_pos_H = round(library_file.loc[:, 'mass'] + PROTON).astype(int)\n",
    "    )\n",
    "    list_suspects.sort_values(by='mass', inplace=True)\n",
    "\n",
    "    # 5. Suspect List Matches\n",
    "    def search_suspect_list(input_file, list_suspects, ppm_error):\n",
    "        matches = pd.DataFrame()\n",
    "        \n",
    "        for index, row in input_file.iterrows():\n",
    "            \n",
    "            LOWER = row['peak_location'] - row['peak_location'] * ppm_error / 1E6\n",
    "            UPPER = row['peak_location'] + row['peak_location'] * ppm_error / 1E6\n",
    "                    \n",
    "            temp_matches = list_suspects[(list_suspects['mz_pos_H'] >= LOWER) & (list_suspects['mz_pos_H'] <= UPPER)]\n",
    "            \n",
    "            if len(temp_matches):\n",
    "                new_df = temp_matches.copy()\n",
    "                new_df.loc[:, 'exper_mz'] = row['peak_location']\n",
    "                new_df.loc[:, 'height'] = row['peak_height']\n",
    "                new_df.loc[:, 'abund'] = row['scaled_abundance']\n",
    "                new_df.loc[:, 'exp_KMD_CF2'] = row['KMD_CF2']\n",
    "                new_df.loc[:, 'exp_KMD_CH2'] = row['KMD_CH2']\n",
    "                new_df.loc[:, 'exp_KMD_C2H4O'] = row['KMD_C2H4O']\n",
    "                new_df.loc[:, 'S/N'] = row['s/n']\n",
    "                new_df.loc[:, 'ppm_error'] = 1E6 * (row['peak_location'] - temp_matches['mz_pos_H']) / temp_matches['mz_pos_H']          \n",
    "                matches = pd.concat([matches, new_df])\n",
    "                \n",
    "        return matches\n",
    "\n",
    "    results = search_suspect_list(input_file, list_suspects, ppm_error)\n",
    "    \n",
    "    # 6. Reformat and Print Results\n",
    "    results.rename(columns={'chemical_name': 'name'}, inplace=True)\n",
    "    results.rename(columns={'mass': 'lib_mass'}, inplace=True)\n",
    "    results.rename(columns={'mz_pos_H': 'library_pos_mz'}, inplace=True)\n",
    "    results.rename(columns={'c': 'C'}, inplace=True)\n",
    "    results.rename(columns={'h': 'H'}, inplace=True)\n",
    "    results.rename(columns={'br': 'Br'}, inplace=True)\n",
    "    results.rename(columns={'cl': 'Cl'}, inplace=True)\n",
    "    results.rename(columns={'f': 'F'}, inplace=True)\n",
    "    results.rename(columns={'i': 'I'}, inplace=True)\n",
    "    results.rename(columns={'n': 'N'}, inplace=True)\n",
    "    results.rename(columns={'o': 'O'}, inplace=True)\n",
    "    results.rename(columns={'p': 'P'}, inplace=True)\n",
    "    results.rename(columns={'s': 'S'}, inplace=True)\n",
    "    results.rename(columns={'dbe': 'DBE'}, inplace=True)\n",
    "    results.columns\n",
    "    results = results.loc[:, ['name', 'exper_mz', 'height', 'abund', 'lib_mass', 'ppm_error', 'S/N', 'formula', \n",
    "                            'C', 'H', 'Br', 'Cl', 'F', 'I', 'N', 'O', 'P', 'S', 'DBE']]\n",
    "    results = results.reset_index()\n",
    "    \n",
    "    # Remove those don't have 'H' (which means they can't be deprotonated)\n",
    "    # results.drop_duplicates(subset=['formula'],inplace=True)\n",
    "    results = results.loc[results['formula'].str.contains('H')]\n",
    "    \n",
    "    #Count the number of unique peaks have assigned\n",
    "    num_unique = results.loc[:, 'exper_mz'].nunique()\n",
    "\n",
    "    # 7. Check the isotopologue\n",
    "    ## 7a. Define isotopes and calculate iso mass\n",
    "    C_mass = 12.000000\n",
    "    Br_mass = 78.918336\n",
    "    Cl_mass = 34.968853\n",
    "    O_mass = 15.994915\n",
    "    S_mass = 31.972072\n",
    "    # Define the isotopes:\n",
    "    C_13_mass = 13.003355\n",
    "    C_13_abund = 0.0107/0.9893\n",
    "    Br_81_mass = 80.916290\t\n",
    "    Br_81_abund = 0.4931/0.5069\n",
    "    Cl_37_mass = 36.965903\t\n",
    "    Cl_37_abund = 0.2423/0.7577\n",
    "    O_18_mass = 17.999159\t\n",
    "    O_18_abund = 0.0020/0.99757\n",
    "    S_34_mass = 33.967868\n",
    "    S_34_abund = 0.0421/0.9493\n",
    "              \n",
    "    results.loc[results['C'] > 0, '13C_mass'] = results['exper_mz'] + (C_13_mass - C_mass)\n",
    "    results.loc[results['Br'] > 0, '81Br_mass'] = results['exper_mz'] + (Br_81_mass - Br_mass)\n",
    "    results.loc[results['Cl'] > 0, '37Cl_mass'] = results['exper_mz'] + (Cl_37_mass - Cl_mass)\n",
    "    results.loc[results['S'] > 0, '34S_mass'] = results['exper_mz'] + (S_34_mass - S_mass)\n",
    "    results.loc[results['O'] > 0, '18O_mass'] = results['exper_mz'] + (O_18_mass - O_mass)\n",
    "\n",
    "    results.loc[results['C'] > 0, '13C_abund'] = results['abund'] * results['C'] * C_13_abund\n",
    "    results.loc[results['Br'] > 0, '81Br_abund'] = results['abund'] * results['Br'] * Br_81_abund\n",
    "    results.loc[results['Cl'] > 0, '37Cl_abund'] = results['abund'] * results['Cl'] * Cl_37_abund\n",
    "    # results.loc[results['Cl'] > 0, '37Cl2_abund'] = results['abund'] * results['Cl'] * (results['Cl'] - 1)/2 * Cl_37_abund * Cl_37_abund\n",
    "    results.loc[results['S'] > 0, '34S_abund'] = results['abund'] * results['S'] * S_34_abund\n",
    "    results.loc[results['O'] > 0, '18O_abund'] = results['abund'] * results['O'] * O_18_abund\n",
    "    \n",
    "    ## 7b. Search for isotope peaks\n",
    "    def search_isotope(results, column_name, intensity_error):\n",
    "        results[column_name + '_iso?'] = ''\n",
    "        results[column_name + '_abund?'] = ''\n",
    "        results[column_name + '_abund_err?'] = ''\n",
    "        results[column_name + '_match?'] = ''\n",
    "        \n",
    "        for i, row in results.iterrows():\n",
    "            ppm_lower_bound = row[column_name + '_mass'] - row[column_name + '_mass'] * ppm_error / 1E6\n",
    "            ppm_upper_bound = row[column_name + '_mass'] + row[column_name + '_mass'] * ppm_error / 1E6\n",
    "            intensity_lower_bound = row[column_name + '_abund'] * (1 - intensity_error)\n",
    "            intensity_upper_bound = row[column_name + '_abund'] * (1 + intensity_error)\n",
    "            # Check if any 'peaklist' value in raw data CSV falls within the range\n",
    "            match = ((input_file['peak_location'] >= ppm_lower_bound) & \n",
    "                    (input_file['peak_location'] <= ppm_upper_bound) & \n",
    "                    (input_file['scaled_abundance'] > intensity_lower_bound) & \n",
    "                    (input_file['scaled_abundance'] < intensity_upper_bound))\n",
    "            \n",
    "            if any(match):\n",
    "                # Get the matching 'peak_location' and 'scaled_abundance' values\n",
    "                matched_peak_location = input_file.loc[match, 'peak_location'].values[0]\n",
    "                matched_scaled_abundance = input_file.loc[match, 'scaled_abundance'].values[0]\n",
    "                abundance_error = ((matched_scaled_abundance - row[column_name + '_abund']) / row[column_name + '_abund']).round(4)\n",
    "                # Assign the matched values to the respective columns\n",
    "                results.at[i, column_name + '_iso?'] = matched_peak_location\n",
    "                results.at[i, column_name + '_abund?'] = matched_scaled_abundance\n",
    "                results.at[i, column_name + '_abund_err?'] = abundance_error\n",
    "                results.at[i, column_name + '_match?'] = 'Y'\n",
    "        return results\n",
    "        \n",
    "    results = search_isotope(results, '13C', 0.15)\n",
    "    results = search_isotope(results, '81Br', 0.15)\n",
    "    results = search_isotope(results, '37Cl', 0.15)\n",
    "    results = search_isotope(results, '18O', 0.6)\n",
    "    results = search_isotope(results, '34S', 0.3)\n",
    "     \n",
    "    ## 7c. Eliminate those assignments that contain Br/Cl/S/C but the isotopologue does not match. *Keep all if abundance of isotopologue < minimum\n",
    "    #           those don't have this elem   those isotopologues match          those isopeak's abundance is < minimum\n",
    "    results = results[(results['Br'] < 1) | (results['81Br_match?'] == 'Y') | ((results['Br'] >= 1) & (results['abund'] < results['abund'].min() / (results['Br'] * Br_81_abund)))]\n",
    "    results = results[(results['Cl'] < 1) | (results['37Cl_match?'] == 'Y') | ((results['Cl'] >= 1) & (results['abund'] < results['abund'].min() / (results['Cl'] * Cl_37_abund)))]\n",
    "    results = results[(results['O'] < 1) | (results['18O_match?'] == 'Y') | ((results['O'] >= 1) & (results['abund'] < results['abund'].min() / (results['O'] * O_18_abund)))]\n",
    "    results = results[(results['S'] < 1) | (results['34S_match?'] == 'Y') | ((results['S'] >= 1) & (results['abund'] < results['abund'].min() / (results['S'] * S_34_abund)))]\n",
    "    results = results[(results['13C_match?'] == 'Y') | ((results['abund'] < results['abund'].min() / (results['C'] * C_13_abund)))]\n",
    "    # peak_number = results.groupby('exper_mz').ngroup() + 1\n",
    "    assgnmnts_number = len(results.index)\n",
    "    \n",
    "\n",
    "    results['KMD_CF2'] = (results['lib_mass'].round() - results['lib_mass']*50/49.99681).round(4)\n",
    "    results['z*_CF2'] = (results['lib_mass'].round() % 50) - 50\n",
    "\n",
    "    final = results.drop_duplicates(subset=['formula'])\n",
    "    final = final.loc[:, ['name', 'exper_mz', 'height', 'abund', 'lib_mass', 'ppm_error', 'S/N', \n",
    "                            'KMD_CF2', 'z*_CF2', 'formula', 'C', 'H', 'Br', 'Cl', 'F', 'I', 'N', 'O', 'P', 'S', 'DBE', \n",
    "                            '13C_match?', '13C_abund_err?', '81Br_match?', '81Br_abund_err?', '37Cl_match?', '37Cl_abund_err?', \n",
    "                            '18O_match?', '18O_abund_err?', '34S_match?', '34S_abund_err?']]\n",
    "    \n",
    "    final = final.reset_index()\n",
    "    peak_number = final.groupby('exper_mz').ngroup() + 1\n",
    "    assgnmnts_number = len(final.index)\n",
    "    \n",
    "    # 9. Add counter columns for some stat numbers\n",
    "    # peak_number_after_KMD = results_unique.groupby('exper_mz').ngroup() + 1\n",
    "    # final['peak_number'] = peak_number_after_KMD\n",
    "    # final = final.sort_values('peak_number')\n",
    "    # results['assignment_number'] = results.groupby('exper_mz').cumcount() + 1     # This counts the # of assignments of a peak\n",
    "    final.loc[0, '#raw_pks'] = int(raw_pks)\n",
    "    final.loc[0, '#lib_pks'] = int(lib_pks)\n",
    "    final.loc[0, '#matched_pks'] = int(peak_number.max())\n",
    "    final.loc[0, '#assgnmnts'] = int(assgnmnts_number)\n",
    "\n",
    "    final.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cec5941f0688b3f557496887f5c49485f247af72e7e23cdf1eef947bedb93c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
